install.packages("pwr", repos="http://cran.r-project.org")
library(pwr)
?pwr
pwr.p.test(h = ES.h(p1 = 0.75, p2 = 0.50),
sig.level = 0.05,
power = 0.80,
alternative = "greater")
pwr.p.test(h = ES.h(p1 = 0.75, p2 = 0.50),
sig.level = 0.05,
power = 0.95,
alternative = "greater")
?pwr.p.test
t.test(x)
install.packages('rvest')
library(rvest)
url <- https://www.google.sk/maps/place/Kaufland/@48.6999196,21.243121,14z/data=!4m8!1m2!2m1!1skaufland!3m4!1s0x473ee0403a7d2069:0xa27ccfc19e6194ec!8m2!3d48.7152495!4d21.2375211
url <- https:www.google.sk/maps/place/Kaufland/@48.6999196,21.243121,14z/data=!4m8!1m2!2m1!1skaufland!3m4!1s0x473ee0403a7d2069:0xa27ccfc19e6194ec!8m2!3d48.7152495!4d21.2375211
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
url<- 'https://www.google.sk/maps/place/Kaufland/@48.6999196,21.243121,14z/data=!4m8!1m2!2m1!1skaufland!3m4!1s0x473ee0403a7d2069:0xa27ccfc19e6194ec!8m2!3d48.7152495!4d21.2375211'
webpage <- read_html(url)
rank_data_html <- html_nodes(webpage,'.section-popular-times-value , .section-popular-times-live-value-gradient , .section-popular-times-arrow-right')
rank_data <- html_text(rank_data_html)
head(rank_data)
rank_data_html <- html_nodes(webpage,'..section-popular-times-bar , .section-popular-times-arrow-left')
rank_data_html <- html_nodes(webpage,'.section-popular-times-graph-visible')
rank_data <- html_text(rank_data_html)
head(rank_data)
rank_data_html
install.packages("skmeans",dependencies = TRUE)
library(skmeans)
?skmeans
lek<-read.csv(file.choose())
str(lek)
plot(lek$kusy,lek$hodiny)
lek.clusters<-skmeans(lek,4,method = "genetic")
led.stand <- scale(lek[-1])
?scale
?kmeans
lek.cluster <- kmeans(lek[,c("trzby","kusy","hodiny")], centers=3, nstart=10)
lek.cluster <- kmeans(lek[,c("trzby","kusy","hodiny")], centers=3)
lek.scale<-scale(lek)
lek.df<-data.frame(lek,lek$trzby,lek$kusy,lek$hodiny)
str(lek.df)
lek.df<-data.frame(lek)
str(lek.df)
lek.cl<-kmeans(lek.df)
lek.cl<-kmeans(lek.df,centers = 3)
?kmeans
lek.cl<-kmeans(lek.df,3)
plot(kusy~hodiny,lek)
set.seed(1234)
data("iris")
str(iris)
summary(iris)
ir3 <- kmeans(iris[,-5], centers=3)
ir3
table(ir3$cluster, iris$Species)
library(cluster)
s <- silhouette(ir3$cluster, dist(iris[,-5]))
plot(s)
d <- dist(scale(iris[,-5]))
d
h <- hclust(d)
plot(h)
?rpartXse
?rpart
library(DMwR2)
install.packages(DMwR2)
library("rpart", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library(devtools)
install.packages("devtools")
library(devtools)
install_github("ltorgo/DMwR2",ref="master")
library(DMwR2)
data("iris")
ct1 <- rpartXse(Species ~ ., iris)
ct2 <- rpartXse(Species ~ ., iris, se=0)
library(rpart.plot)
install.packages("rpart.plot")
prp(ct1, type=0, extra=101)
library(rpart.plot)
prp(ct1, type=0, extra=101)
prp(ct2, type=0, extra=101)
call dev.off()
calldev.off()
dev.off()
dev.off()
dev.off()
dev.on()
dev.off()
library(rpart.plot)
prp(ct1, type=0, extra=101)
sessionInfo()
rstudio::versionInfo()
install.packages("KernSmooth")
library(KernSmooth)
x<-1:4
?lapply
lapply(x,runif)
x <- matrix(rnorm(200),20,10)
x
apply(x,1,mean)
apply(x,1,sum)
swir\\
swirl()
library(swirl)
ls()
rm(list = ls())
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags,class)
cls_list
class(cls_list)
as.character(cls_list)
sapply(flags,class)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors,sum())
lapply(flag_colors,sum)
sapply(flag_colors,sum)
sapply(flag_colors,mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes,range)
sapply(flag_shapes,range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,6,6))
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags,unique)
unique_vals
lapply(unique_vals,lenght)
lapply(unique_vals,length)
sapply(unique_vals,length)
lapply(unique_vals,length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class,character(1))
>tapply()
?tapply()
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate,flags$landmass, mean)
tapply(flags$population, flags$red, summary)
21
tapply(flags$population, flags$landmass, summary)
rm(list = ls())
library(datasets)
data(iris)
?iris
head(iris)
lapply(iris,mean)
lapply(iris$Species,mean)
View(iris)
lapply(iris$Sepal.Length,mean)
sapply(iris, class)
mean(iris[iris$Species=="virginica",1])
mean(iris$Sepal.Length[iris$Species=='virginica'])
apply(iris[,1:4],2,mean)
library(datasets)
data(mtcars)
head(mtcars)
mean(mtcars$mpg,mtcars$cyl)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
?split
sapply(split(mtcars$hp, mtcars$cyl), mean)
209.21429-8263636
209.21429-82.63636
debug(ls)
debug(ls)
rm(list = ls())
swirl()
library(swirl)
swirl()
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
group_by(package)
?group_by
by_package<-group_by(cran,package)
by_package
summarise(by_package,mean(size))
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size))
submit()
skip()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts<-filter(pack_sum$count>679)
top_counts<-filter(pack_sum,count>679)
top_counts
View(top_counts)
arrange(top_counts,desc(count))
top_counts_sorted<-arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99).
quantile(pack_sum$unique, probs = 0.99)
top_unique<-filter(top_counts,unique>465)
top_unique<-filter(pack_sum,unique>465)
View
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
skip()
skip()
skip()
View(result3)
skip()
skip()
skip
skip()
skip()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
gather(students2,sex_class,count,-grade)
skip()
res
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
info()
rm(list = ls())
data<-read_csv(file.choose())
str(data)
summary(data)
names(data)
library(dplyr)
agricultureLogical<-subset(data,ACR==3,AGS==6)
agricultureLogical[1:10]
View(agricultureLogical)
agricultureLogical<-filter(data,ACR==3,AGS==6)
agricultureLogical <- data$ACR == 3 & data$AGS == 6
which(agricultureLogical)[1:3]
?which
install.packages("jpeg")
libratr
library(jpeg)
?jpeg
getwd
getwd()
dir()
setwd("/Users/mariansvatko/Desktop")
img<-readJPEG(jeff,native = TRUE)
img<-readJPEG(j,native = TRUE)
getwd
getwd()
setwd("/Users/mariansvatko/R_data")
img<-readJPEG(j,native = TRUE)
getwd()
img<-readJPEG(ABC,native = TRUE)
dir()
img<-readJPEG(ABC.jpg,native = TRUE)
img<-readJPEG("ABC",native = TRUE)
img<-readJPEG("ABC",native = TRUE)
img<-readJPEG("ABC.jpg",native = TRUE)
quantile(img,probs = c(0.3,0.8))
rm(list = ls())
GDP<-read_csv(file.choose())
EDSTATS<-read_csv(file.choose())
names(GDP)
summary(GDP)
head(GDP)
head(EDSTATS)
?melt
library(reshape2)
?melt
?merge
rename(GDP,X1,"CountryCode")
rename(GDP,"X1","CountryCode")
rename?rname
?rename
rename(GDP$X1,"CountryCode")
GDP$X1<-as.character(GDP$X1)
rename(GDP$X1,"CountryCode")
rm(list = ls())
GDP<-read.csv(file.choose())
ESP<-read.csv(file.choose())
names(GDP)
names(ESP)
?merge
dt<-merge(GDP,ESP,"CountryCode")
head(dt)
str(dt)
str(GDP)
str(ESP)
head(dt)
sum(!is.na(unique(dt$Rank)))
dt<-arrange(dt,Rank)
dt<-arrange(dt,desc(Rank))
View(dt)
class(dt$Rank)
dt$Rank<-as.integer(dt$Rank)
dt<-arrange(dt,desc(Rank))
View(dt)
mean(dt$GDP,dt$Income.Group=="High income: OECD")
A<-filter(dt,Income.Group=="High income: OECD")
mean(A$GDP)
head(A)
filter(A,mean(GDP))
summary(A$GDP)
str(A$GDP)
A$GDP<-as.numeric(A$GDP)
filter(A,mean(GDP))
summary(A)
dt[, mean(rankingGDP, na.rm = TRUE), by = Income.Group]
dt[, mean(Rank, na.rm = TRUE), by = Income.Group]
str(dt)
dt[, mean(Rank, na.rm = TRUE), by = dt$Income.Group]
dt[, mean(Rank, na.rm = TRUE)]
dt[, mean(dt$Rank, na.rm = TRUE)]
dt[mean("Rank",na.rm = TURE)]
dt[mean(Rank,na.rm = TURE)]
dt[mean(dt$Rank,na.rm = TURE)]
dt[dt$Rank][1:6]
dt[,dt$Rank][1:6]
dt[,Rank][1:6]
dt[,"CountryCode"=="PAN"]
dt[,"Rank"]
dt[,"Rank","Income.Group"=="High income: nonOECD"]
dt[,mean("Rank"),"Income.Group"=="High income: nonOECD"]
H<-dt[,"Rank","Income.Group"=="High income: nonOECD"]
mean()H
mean(H)
H<-!is.na()
H<-!is.na(H)
mean(H)
H
H<-dt[,"Rank","Income.Group"=="High income: nonOECD"]
H
mean(H$Rank)
dt[, mean("Rank", na.rm = TRUE), by = Income.Group]
dt[, mean("Rank", na.rm = TRUE), by = "Income.Group"]
H<-filter(dt,Income.Group=="High income: nonOECD")
H
mean(H$Rank)
summary(H)
H<-filter(dt,Income.Group=="High income: OECD")
mean(H$Rank)
summary(H$Income.Group)
head(H)
tail(H)
str(H)
rm(list = ls())
getwd()
setwd("/Users/mariansvatko/datasciencecoursera")
dir.create("./data")
getwd()
dir.create(".../data")
dir.create("./data")
fileUrlL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "./Data.zip")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "./Data.zip")
getwd()
setwd()
setwd("/Users/mariansvatko/datasciencecoursera/Getting and Cleaning Data Project/data")
unzip("./data/Data.zip", exdir = "./data")
unzip("./data/Data.zip")
unzip("Data.zip")
train_x <- read.table("./data/UCI HAR Dataset/train/X_train.txt")
train.y <- read.table("./data/UCI HAR Dataset/train/y_train.txt")
train_y <- read.table("./data/UCI HAR Dataset/train/y_train.txt")
train_subject <- read.table("./data/UCI HAR Dataset/train/subject_train.txt")
test_x <- read.table("./data/UCI HAR Dataset/test/X_test.txt")
test_y <- read.table("./data/UCI HAR Dataset/test/y_test.txt")
test_subject <- read.table("./data/UCI HAR Dataset/test/subject_test.txt")
trainData <- cbind(train_subject, train_y, train_x)
testData <- cbind(test_subject, test_y, test_x)
allData <- rbind(trainData, testData)
?sdev
stdev
?sdev
?sd
featureName <- read.table("./data/UCI HAR Dataset/features.txt", stringsAsFactors = FALSE)[,2]
featureName
?grep
featureIndex <- grep(("mean\\(\\)|std\\(\\)"), featureName)
featureIndex
finalData <- fullData[, c(1, 2, featureIndex+2)]
finalData <- allData[, c(1, 2, featureIndex+2)]
colnames(finalData) <- c("subject", "activity", featureName[featureIndex])
head(finalData)
allData <- rbind(trainData, testData)
head(allData)
names(allData)
finalData <- allData[, c(1, 2, featureIndex+2)]
names(allData)
colnames(finalData) <- c("subject", "activity", featureName[featureIndex])
activityName <- read.table("./data/UCI HAR Dataset/activity_labels.txt")
?factor
finalData$activity
finalData$activity <- factor(finalData$activity, levels = activityName[,1], labels = activityName[,2])
?gsub
names(finalData) <- gsub("\\()", "", names(finalData))
names(finalData) <- gsub("^t", "time", names(finalData))
names(finalData) <- gsub("^f", "frequence", names(finalData))
names(finalData) <- gsub("-mean", "Mean", names(finalData))
names(finalData) <- gsub("-std", "Std", names(finalData))
library(dplyr)
groupData <- finalData %>%
group_by(subject, activity) %>%
summarise_each(funs(mean))
groupData <- finalData %>%
group_by(subject, activity) %>%
summarise_all(funs(mean))
write.table(groupData, "./Getting_and_Cleaning_data_Project/MeanData.txt", row.names = FALSE)
write.table(groupData, "./MeanData.txt", row.names = FALSE)
mean_data<- read.table(MeanData.txt)
setwd()
setwd('..')
mean_data<- read.table(MeanData.txt)
dir()
getwd()
setwd("/Users/mariansvatko/datasciencecoursera/Getting and Cleaning Data Project/data")
mean_data<- read.table(MeanData.txt)
mean_data<- read.table(MeanData.txt)
setwd('..')
mean_data<- read.table(MeanData.txt)
mean_data<- read.table(file.choose())
head(mean_data)
names(mean_data)
?codebook
install.packages("memisc")
?codebook
??codebook
codebook(run_analysis.R)
?knit
??knit
install.packages("knitr")
library(knitr)
knit(run_analysis.R)
knit("makeCodebook.Rmd", output="codebook.md", encoding="ISO8859-1", quiet=TRUE)
install.packages("markdown")
library(markdown)
knit(Codebook.md)
str(mean_data)
mean_data<- read.table(file.choose())
head(mean_data)
str(mean_data)
summary(mean_data)
rm(list = ls())
dir()
train_x <- read.table("./data/UCI HAR Dataset/train/X_train.txt")
getwd()
setwd("/Users/mariansvatko/datasciencecoursera/Getting and Cleaning Data Project/data")
train_x <- read.table("./data/UCI HAR Dataset/train/X_train.txt")
summary(train_x)
names(train_x)
head(train_x)
train_y <- read.table("./data/UCI HAR Dataset/train/y_train.txt")
train_subject <- read.table("./data/UCI HAR Dataset/train/subject_train.txt")
test_x <- read.table("./data/UCI HAR Dataset/test/X_test.txt")
test_y <- read.table("./data/UCI HAR Dataset/test/y_test.txt")
test_subject <- read.table("./data/UCI HAR Dataset/test/subject_test.txt")
trainData <- cbind(train_subject, train_y, train_x)
testData <- cbind(test_subject, test_y, test_x)
allData <- rbind(trainData, testData)
featureName <- read.table("./data/UCI HAR Dataset/features.txt", stringsAsFactors = FALSE)[,2]
featureIndex <- grep(("mean\\(\\)|std\\(\\)"), featureName)
finalData <- allData[, c(1, 2, featureIndex+2)]
colnames(finalData) <- c("subject", "activity", featureName[featureIndex])
activityName <- read.table("./data/UCI HAR Dataset/activity_labels.txt")
finalData$activity <- factor(finalData$activity, levels = activityName[,1], labels = activityName[,2])
names(finalData) <- gsub("\\()", "", names(finalData))
names(finalData) <- gsub("^t", "time", names(finalData))
names(finalData) <- gsub("^f", "frequence", names(finalData))
names(finalData) <- gsub("-mean", "Mean", names(finalData))
names(finalData) <- gsub("-std", "Std", names(finalData))
library(dplyr)
groupData <- finalData %>%
group_by(subject, activity) %>%
summarise_all(funs(mean))
write.table(groupData, "./MeanData.txt", row.names = FALSE)
str(activityName)
head(activityName)
?group_by
library(dplyr)
groupData <- finalData %>%
group_by(subject, activityName[,2]) %>%
summarise_all(funs(mean))
tidy <- read.table(file.choose())
head(tidy)
names(tidy)
str(tidy)
str(finalData)
?source
source('run_analysis.R')
setwd('..')
source('run_analysis.R')
str(tidy)
names(tidy)
tidy
finalData
rm(list = ls())
train_x <- read.table("./data/UCI HAR Dataset/train/X_train.txt")
getwd()
